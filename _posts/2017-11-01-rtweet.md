---
title: "Collecting tweets with R and {rtweet}"
author: colin_fay
post_date: 2017-11-01
layout: single
permalink: /collect-rtweet/
categories : r-blog-en
excerpt_separator: <!--more-->
---

Some arguments in favor of [{rtweet}](https://CRAN.R-project.org/package=rtweet ), an amazing package by Michael W. Kearney. 

<!--more-->

> Note: this post has been updated after recent changes in the {rtweet} package

For what I remember, I have been scraping web data for as long as I've been using R. This, of course, includes Google Analytics, Facebook, raw web pages, and so on and so forth — but most of all, I've always loved playing with Twitter data. I've been on Twitter for [8 years now](https://twitter.com/_ColinFay/status/922304944971173888), and I know what an insightful place it can be, and also, it's full of data, so you know, why not going down that rabbit hole! 

## A long time ago, in a far away land

My first encounter with tweet collecting in R has been through the {twitteR} package, which, despite its (sometimes) weird interface and strange functions, has been really useful in many past projects.

So, before {rtweet}, the common practice was to mine Twitter with {twitteR}, which was designed as an object oriented package (so not tidy): calls on the API create environments, in which you can use methods for further investigation. Also, results were not in a data.frame format (even if there is a funtion to turn twitter lists to df). 

Searching for tweets was quite straightforward: setting up oauth, search twitter, convert result to dataframe, dealing with dates... but a drawback was when doing text mining: you had to look for hashtags by subsetting the raw text messages of tweets. That could be kind of a headache. Not to mention when you needed to retrieve followers, timelines, and everything that makes Twitter a richful place to mine for data. 

## Why I used rtweet? 


I've been using rtweet for several projects now, the more recent being: 

+ [#BreizhDataDay, revue de Tweets](http://breizhdataclub.org/breizhdataday-revue-de-tweets/) 

which I wrote just after the first [Breizh Data Day](https://breizhdataday.github.io/). 

So, {rtweet} is a (relatively) young package, as it was first published on CRAN around a year ago (august 2016). It provides a tidy approach to collecting Twitter data: main functions return a data.frame following the [tidy data](http://vita.had.co.nz/papers/tidy-data.html) principles.

A cool thing also, is that you don't need to set up a Twitter app in order to search for tweets.

## {rtweet} worklow

So, let's try searching for 1000 tweets with the hashtag Rennes with {rtweet}.

```r
library(rtweet)
srch <- search_tweets("#Rennes", n = 1000)
Searching for tweets...
Finished collecting tweets!
  
dplyr::glimpse(srch)
Observations: 996
Variables: 42
$ status_id              <chr> "953212457077608448", "953211786295209984", "953211780465070080"...
$ created_at             <dttm> 2018-01-16 10:28:54, 2018-01-16 10:26:14, 2018-01-16 10:26:12, ...
$ user_id                <chr> "794964573170368513", "2468141791", "567056039", "2821345930", "...
$ screen_name            <chr> "JeunesMacron87", "RennesEmploi", "Emploi_35", "DELLAVECCHIA4", ...
$ text                   <chr> "RT @BeaudouinSo: Jeudi 11, j'étais à #Rennes en #Bretagne avec ...
$ source                 <chr> "Twitter for iPhone", "Emploi Proximité", "Emploi Proximité", "T...
$ reply_to_status_id     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
$ reply_to_user_id       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
$ reply_to_screen_name   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
$ is_quote               <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F...
$ is_retweet             <lgl> TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE...
$ favorite_count         <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0...
$ retweet_count          <int> 6, 0, 0, 79, 22, 0, 1, 0, 0, 0, 79, 22, 0, 79, 22, 2, 22, 0, 22,...
$ hashtags               <list> [<"Rennes", "Bretagne">, <"rennes", "job", "emploi">, <"rennes"...
$ symbols                <list> [NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA...
$ urls_url               <list> [NA, "emploiilleetvilaine.com/rennes-medecin…", "emploiilleetvi...
$ urls_t.co              <list> [NA, "https://t.co/2lv8EL1TWe", "https://t.co/Nu7gzjbOHL", NA, ...
$ urls_expanded_url      <list> [NA, "https://emploiilleetvilaine.com/rennes-medecin-collaborat...
$ media_url              <list> [NA, NA, NA, NA, NA, NA, NA, NA, "http://pbs.twimg.com/media/DT...
$ media_t.co             <list> [NA, NA, NA, NA, NA, NA, NA, NA, "https://t.co/ziNKbxArT5", NA,...
$ media_expanded_url     <list> [NA, NA, NA, NA, NA, NA, NA, NA, "https://twitter.com/RennesOnl...
$ media_type             <list> [NA, NA, NA, NA, NA, NA, NA, NA, "photo", NA, NA, NA, "photo", ...
$ ext_media_url          <list> [NA, NA, NA, NA, NA, NA, NA, NA, "http://pbs.twimg.com/media/DT...
$ ext_media_t.co         <list> [NA, NA, NA, NA, NA, NA, NA, NA, "https://t.co/ziNKbxArT5", NA,...
$ ext_media_expanded_url <list> [NA, NA, NA, NA, NA, NA, NA, NA, "https://twitter.com/RennesOnl...
$ ext_media_type         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
$ mentions_user_id       <list> ["831910700574457856", NA, NA, "2184489764", "2175883022", "828...
$ mentions_screen_name   <list> ["BeaudouinSo", NA, NA, "Gendarmerie", "GillesPennelle", "Meteo...
$ lang                   <chr> "fr", "fr", "fr", "fr", "fr", "fr", "fr", "fr", "fr", "fr", "fr"...
$ quoted_status_id       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
$ quoted_text            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
$ retweet_status_id      <chr> "952532188305723392", NA, NA, "952976442488389636", "95319840411...
$ retweet_text           <chr> "Jeudi 11, j'étais à #Rennes en #Bretagne avec ma commission pou...
$ place_url              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
$ place_name             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
$ place_full_name        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
$ place_type             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
$ country                <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
$ country_code           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ...
$ geo_coords             <list> [<NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <N...
$ coords_coords          <list> [<NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <N...
$ bbox_coords            <list> [<NA, NA, NA, NA, NA, NA, NA, NA>, <NA, NA, NA, NA, NA, NA, NA,...
```

And here it is. Yes, it's that simple: 1000 tweets in two commands (and one being `library()`): __without specifying any oauth token__. 

So now we have a tidy data.frame with the results, hashtags are in a column we can easily parse and count, as are text, mentions, and everything needed to start mining data. 

### Quick example

> Note: the recent version of {rtweet} returns a list column, which is not handled by `unnest_tokens`. 

We can write a quick hashtag and sentiment analysis : 

```r
library(dplyr)
library(purrr)
library(proustr)
library(tidytext)

srch %>%
   modify_if(is.list, ~ simplify(.x) %>% paste(collapse = " "))  %>%
   unnest_tokens(word, hashtags) %>%
   count(word, sort = TRUE) %>% 
   top_n(5)
Selecting by n
# A tibble: 5 x 2
      word       n
     <chr>   <int>
1   rennes 1016916
2 bretagne   96612
3    brest   78684
4    stups   69720
5    udvie   49800

srch %>% 
   modify_if(is.list, ~ simplify(.x) %>% paste(collapse = " ")) %>%
   unnest_tokens(word, text) %>%
   select(word) %>%
   left_join(proust_sentiments(type = "score")) %>%
   na.omit() %>%
   count(sentiment)
Joining, by = "word"
# A tibble: 6 x 2
  sentiment     n
      <chr> <int>
1     anger   188
2   disgust   130
3      fear   246
4       joy   132
5   sadness   239
6  surprise   198
```

Of course {rtweet} is full of other features you can try. But that blog post was more of an introduction, and I hope I've convinced you to download and use this amazing package!